{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PBKcat\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title clone and download dependencies\n",
    "! git clone https://github.com/950288/PBkcat_test.git\n",
    "! cd PBkcat_test\n",
    "! pip install -r dependencies.txt\n",
    "! wget ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/epoch_92400_sample_23500000.pkl ./preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title preprocess substrate\n",
    "! python ./preprocess/substrate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title preprocess protein\n",
    "! python ./preprocess/proteinBERT_local_rep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title train model\n",
    "import model.model as model\n",
    "import torch\n",
    "import random\n",
    "import timeit\n",
    "import json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model_name = 'Kcat'\n",
    "\n",
    "    args = {\n",
    "        \"dim\" : 10,\n",
    "        \"layer_output\" : 3,\n",
    "        \"layer_gnn\" : 3,\n",
    "        \"layer_dnn\" : 3,\n",
    "        \"lr\" : 1e-3,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"epoch\" : 100\n",
    "    }\n",
    "\n",
    "    file_model = './model/output/' + model_name\n",
    "    file_MAEs  = './model/output/' + model_name + '-MAEs.csv'\n",
    "    file_args  = './model/output/' + model_name + '-args.json'\n",
    "\n",
    "    dir_input = './data/'\n",
    "    compound_fingerprints = model.load_pickle(dir_input + 'compound_fingerprints.pickle')\n",
    "    adjacencies = model.load_pickle(dir_input + 'adjacencies.pickle')\n",
    "    proteins_local = model.load_pickle(dir_input + 'local_representations.pickle')\n",
    "    # proteins_global = model.load_pickle(dir_input + 'global_representations.pickle')\n",
    "    fingerprint_dict = model.load_pickle(dir_input + 'fingerprint_dict.pickle')\n",
    "    args['len_fingerprint'] = len(fingerprint_dict)\n",
    "    Kcat = model.load_pickle(dir_input + 'Kcats.pickle')\n",
    "    Kcat = torch.LongTensor(Kcat)\n",
    "\n",
    "    if not (len(compound_fingerprints) == len(adjacencies) == len(proteins_local) == len(Kcat)):\n",
    "        print('The length of compound_fingerprints, adjacencies and proteins are not equal !!!')\n",
    "        exit()\n",
    "\n",
    "    dataset = list(zip(compound_fingerprints, adjacencies, proteins_local, Kcat))\n",
    "    random.shuffle(dataset)\n",
    "    dataset_train, dataset_ = model.split_dataset(dataset, 0.8)\n",
    "    dataset_dev, dataset_test = model.split_dataset(dataset_, 0.5)\n",
    "\n",
    "    \"\"\"CPU or GPU.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print('The code uses GPU !!!')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('The code uses CPU !!!')\n",
    "\n",
    "    torch.manual_seed(random.randint(1, 10000))\n",
    "    Kcatpredictor = model.KcatPrediction(args, device).to(device)\n",
    "    trainer = model.Trainer(Kcatpredictor)\n",
    "    tester = model.Tester(Kcatpredictor)\n",
    "\n",
    "    \"\"\"Output files.\"\"\"\n",
    "    with open(file_args, 'w') as f:\n",
    "        f.write(str(json.dumps(args)) + '\\n')\n",
    "\n",
    "    \"\"\"Start training.\"\"\"\n",
    "    print('Training...')\n",
    "    MAEs = []\n",
    "    start = timeit.default_timer()\n",
    "    for epoch in range(0, args[\"epoch\"]):\n",
    "        print('Epoch: %d / %d' % (epoch + 1, args[\"epoch\"]))\n",
    "        LOSS_train, RMSE_train, R2_train = trainer.train(dataset_train)\n",
    "        LOSS_test, RMSE_test, R2_test = tester.test(dataset_dev)\n",
    "        end = timeit.default_timer()\n",
    "        time = end - start\n",
    "        MAE = [epoch+1, time, LOSS_train, RMSE_train, R2_train, \n",
    "                            LOSS_test,  RMSE_test,  R2_test]\n",
    "        MAEs.append(MAE)\n",
    "\n",
    "    \"\"\"Save the trained model.\"\"\"\n",
    "    torch.save(Kcatpredictor.state_dict(), file_model + \".pth\")\n",
    "    print('Model saved to %s' % file_model)\n",
    "\n",
    "    \"\"\"save MAEs as csv file\"\"\"\n",
    "    with open(file_MAEs, 'w') as f:\n",
    "        f.write('epoch, time, LOSS_train, RMSE_train, R2_train, LOSS_test, RMSE_test, R2_test\\n')\n",
    "        for MAE in MAEs:\n",
    "            f.write(str(MAE)[1:-1] + '\\n')\n",
    "    print('MAEs saved to %s' % file_MAEs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
